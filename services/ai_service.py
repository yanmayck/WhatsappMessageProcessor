import os
import json
import logging
import time
from typing import Dict, Any, List, Optional
import tempfile
import subprocess
import uuid

from agno.agent import Agent
from agno.models.google import Gemini
from agno.team import Team
from services.geolocation_service import GeolocationService
from pydub import AudioSegment
from pydub.exceptions import CouldntDecodeError

from config import Config

logger = logging.getLogger(__name__)

try:
    from google.ai.generativelanguage import Part, Blob as InlineData
    GOOGLE_GEMINI_PARTS_AVAILABLE = True
except ImportError:
    GOOGLE_GEMINI_PARTS_AVAILABLE = False
    Part = None
    InlineData = None
    if logger:
        logger.warning("Could not import Part/Blob from google.ai.generativelanguage. Multimodality may not work as expected.")
    else:
        print("WARNING: Could not import Part/Blob from google.ai.generativelanguage.")

class AIService:
    def __init__(self):
        self.model_name = Config.GEMINI_API_KEY and "gemini-1.5-flash-latest"
        self.api_key = Config.GEMINI_API_KEY

        if not self.api_key:
            logger.error("GEMINI_API_KEY is not configured. AIService will not work.")
            raise ValueError("GEMINI_API_KEY is required for AIService.")

        self.geolocation_service = GeolocationService()

        # --- Constru√ß√£o Din√¢mica do Prompt Conversacional ---
        # As se√ß√µes s√£o combinadas para criar um guia de comportamento completo e personaliz√°vel para a IA.
        conversational_prompt = f"""
        Voc√™ √© {Config.AI_NAME}, um assistente de IA para conversas no WhatsApp.

        ---
        **CONTEXTO DO NEG√ìCIO:**
        {Config.AI_BUSINESS_CONTEXT}
        ---
        **üéØ PERSONALIDADE E TOM:**
        Sua personalidade deve ser: {Config.AI_PERSONALITY_DESCRIPTION}
        ---
        **‚ö° ESTILO DE RESPOSTA:**
        {Config.AI_RESPONSE_STYLE}
        ---
        **üí° HABILIDADES GERAIS:**
            - Responda perguntas de forma clara e concisa. Ofere√ßa ajuda e use exemplos.
        - Mantenha conversas envolventes e naturais.
        ---
        **‚ö†Ô∏è REGRAS DE ESCALONAMENTO PARA ATENDIMENTO HUMANO:**
            - Se o usu√°rio pedir para falar com um humano (ex: 'falar com atendente', 'quero um humano'), sua resposta DEVE incluir o marcador [USER_REQUESTS_HUMAN_AGENT].
            - Se voc√™ n√£o conseguir ajudar, o usu√°rio estiver frustrado, ou a conversa entrar em loop, sua resposta DEVE incluir o marcador [AI_NEEDS_ASSISTANCE].
        - Exemplo de escalonamento pelo usu√°rio: "Entendido! Vou te transferir para um de nossos atendentes. [USER_REQUESTS_HUMAN_AGENT] Por favor, aguarde."
        - Exemplo de escalonamento pela IA: "Hmm, essa √© uma pergunta complexa para mim. [AI_NEEDS_ASSISTANCE] Vou pedir ajuda a um colega humano."
        """

        self.agent_prompts = {
            'conversational': "\n".join([line.strip() for line in conversational_prompt.strip().splitlines()]),
            'visual_analyzer': "Voc√™ √© um assistente visual. Sua fun√ß√£o √© analisar imagens e v√≠deos no contexto de uma conversa. Descreva o que voc√™ v√™ de forma conversacional. Se o usu√°rio fizer uma pergunta, responda com base no conte√∫do visual.",
            'audio_processor': "Sua √∫nica fun√ß√£o √© transcrever o √°udio fornecido com a maior precis√£o poss√≠vel. Apenas retorne o texto transcrito. Se n√£o for fala, descreva os sons (ex: [m√∫sica], [risada]). N√£o adicione nenhuma outra palavra ou frase √† sua resposta.",
            'document_expert': "Voc√™ √© um especialista em an√°lise de documentos. Extraia e estruture informa√ß√µes-chave de PDFs, planilhas e outros documentos.",
            'geolocation_specialist': """Voc√™ √© um assistente IA especializado em calcular fretes e dist√¢ncias.
            - Pe√ßa o endere√ßo de ORIGEM e DESTINO se n√£o forem fornecidos.
            - Se voc√™ receber coordenadas de latitude e longitude, informe ao usu√°rio que voc√™ recebeu a localiza√ß√£o e pe√ßa a informa√ß√£o que falta (o endere√ßo de destino) para poder calcular o frete.
            - Use a ferramenta para calcular dist√¢ncia e custo.
            - Apresente o resultado de forma clara: Dist√¢ncia (km), Dura√ß√£o Estimada e Custo do Frete (R$).
            - Use a ferramenta. N√ÉO invente valores.
            """,
            'profile_manager': """Voc√™ √© um analista de dados silencioso. Sua √∫nica fun√ß√£o √© identificar informa√ß√µes de perfil do usu√°rio na mensagem fornecida e estrutur√°-las em JSON.

            OBJETIVO: Identificar atributos chave que raramente mudam (nome, endere√ßo, telefone, e-mail, prefer√™ncias, etc.). Ignore informa√ß√µes transacionais como "meu √∫ltimo pedido foi X".

            REGRAS DE SA√çDA:
            1.  Sua sa√≠da DEVE SER SEMPRE um objeto JSON v√°lido. N√£o inclua texto explicativo, apenas o JSON.
            2.  Se voc√™ identificar uma informa√ß√£o de perfil, retorne:
                `{"action": "SAVE", "data": {"key": "chave_identificada", "value": "valor_extra√≠do"}}`
            3.  As chaves permitidas s√£o: "name", "address", "email", "phone", "company", "birthday", "preferences".
            4.  Se a mensagem N√ÉO contiver nenhuma informa√ß√£o de perfil clara e acion√°vel, retorne:
                `{"action": "NONE"}`
            
            EXEMPLOS:
            - Mensagem: "Ol√°, meu nome √© Carlos." -> Sa√≠da: `{"action": "SAVE", "data": {"key": "name", "value": "Carlos"}}`
            - Mensagem: "Gostaria de registrar minha prefer√™ncia por chocolate amargo." -> Sa√≠da: `{"action": "SAVE", "data": {"key": "preferences", "value": "prefere chocolate amargo"}}`
            - Mensagem: "Pode me enviar a fatura?" -> Sa√≠da: `{"action": "NONE"}`
            - Mensagem: "meu endere√ßo √© rua das flores 123" -> Sa√≠da: `{"action": "SAVE", "data": {"key": "address", "value": "Rua das Flores, 123"}}`
            """,
            'multimodal_fusion': "Voc√™ √© um especialista em fus√£o multimodal. Combine informa√ß√µes de texto, imagem e √°udio para criar an√°lises hol√≠sticas e contextualizadas."
        }

        self.specialist_agents: Dict[str, Agent] = {}
        agent_list_for_team: List[Agent] = []

        for agent_name_key, system_prompt in self.agent_prompts.items():
            descriptive_name = agent_name_key.replace("_", " ").title()
            tools_for_agent = [self.calculate_shipping_tool] if agent_name_key == 'geolocation_specialist' else None
            gemini_model = Gemini(id=self.model_name, api_key=self.api_key)
            specialist_agent = Agent(
                name=descriptive_name,
                model=gemini_model,
                instructions=[system_prompt],
                role=f"Especialista em {descriptive_name}",
                tools=tools_for_agent,
                expected_output="Uma resposta relevante ou a chamada de uma ferramenta.",
                markdown=False 
            )
            self.specialist_agents[agent_name_key] = specialist_agent
            agent_list_for_team.append(specialist_agent)

        team_model = Gemini(id=self.model_name, api_key=self.api_key)
        team_instructions = [
            "Voc√™ √© um despachante de IA mestre para um chatbot do WhatsApp.",
            "Sua tarefa √© analisar a solicita√ß√£o do usu√°rio e o hist√≥rico da conversa, e encaminhar para o agente especialista mais apropriado da sua equipe.",
            "REGRA DE ROTEAMENTO:",
            "1. Se a entrada contiver uma IMAGEM, encaminhe para o Visual Analyzer.",
            "2. Se a entrada contiver √ÅUDIO, encaminhe para o Audio Processor.",
            "3. Se a inten√ß√£o for sobre FRETE/ENTREGA/DIST√ÇNCIA, encaminhe para o Geolocation Specialist.",
            "4. Para M√öLTIPLOS tipos de m√≠dia, use o Multimodal Fusion.",
            "5. Para todo o resto (conversa geral, texto), use o Conversational Specialist.",
            "Sua sa√≠da final deve ser a resposta do agente especialista escolhido."
        ]
        self.team = Team(
            name="WhatsAppMasterAITeam",
            members=agent_list_for_team,
            model=team_model,
            instructions=team_instructions
        )
        logger.info("AIService inicializado com Master Team e agentes especialistas.")

    def _prepare_text_and_history(self, text: str, conversation_history: Optional[List[Dict[str, Any]]] = None, profile_data: Optional[Dict] = None, location_data: Optional[Dict] = None) -> str:
        history_lines = []
        if conversation_history:
            for msg in conversation_history:
                sender = "Usu√°rio" if msg.get('sender_type') == 'user' else "Assistente"
                content = msg.get('message_text', '').strip()
                if content:
                    history_lines.append(f"{sender}: {content}")
        history_str = "\n".join(history_lines)
        
        final_prompt_parts = []

        if profile_data:
            profile_items = [f"- {key}: {value}" for key, value in profile_data.items()]
            profile_str = "\n".join(profile_items)
            final_prompt_parts.append(f"INFORMA√á√ïES CONHECIDAS SOBRE O USU√ÅRIO (use isso para personalizar a resposta):\n{profile_str}")

        if location_data:
            final_prompt_parts.append(f"LOCALIZA√á√ÉO ATUAL DO USU√ÅRIO (use isso como contexto de origem): Latitude {location_data['latitude']}, Longitude {location_data['longitude']}")

        if history_str:
            final_prompt_parts.append(f"Contexto da conversa anterior:\n{history_str}")
        
        current_message_text = text.strip()
        if current_message_text:
            final_prompt_parts.append(f"Mensagem atual do usu√°rio:\n{current_message_text}")
        
        return "\n\n".join(final_prompt_parts) if final_prompt_parts else "Ol√°."

    def calculate_shipping_tool(self, origin: str, destination: str) -> Dict[str, Any]:
        logger.info(f"[TOOL CALL] calculate_shipping com origem: '{origin}', destino: '{destination}'")
        if not origin or not destination:
            return {"status": "error", "message": "Por favor, forne√ßa os endere√ßos de origem e destino."}

        result = self.geolocation_service.get_distance_and_duration(origin, destination)
        if result:
            distance_km, _, _, duration_text = result
            shipping_fee = self.geolocation_service.calculate_shipping_fee(distance_km)
            response_message = f"C√°lculo para '{origin}' at√© '{destination}':\n- Dist√¢ncia: {distance_km:.2f} km\n- Dura√ß√£o Estimada: {duration_text}\n- Custo do Frete: R$ {shipping_fee:.2f}"
            logger.info(f"Resultado da ferramenta: {response_message}")
            return {"status": "success", "message_to_user": response_message}
        else:
            logger.error(f"Falha ao calcular dist√¢ncia/frete entre '{origin}' e '{destination}'.")
            return {"status": "error", "message": "Desculpe, n√£o consegui calcular o frete. Verifique os endere√ßos."}

    def process_text_message(self, text: str, conversation_history: List[Dict] = None, profile_data: Optional[Dict] = None, location_data: Optional[Dict] = None) -> Dict[str, Any]:
        if not text or not text.strip():
            return {'success': True, 'response': "Ol√°! Como posso te ajudar?", 'metadata': {}}
        
        conversational_agent = self.specialist_agents['conversational']
        # --- L√≥gica de Roteamento Simples ---
        # Se a inten√ß√£o parecer relacionada a frete, usar o especialista.
        # Poder√≠amos usar uma l√≥gica mais avan√ßada aqui, mas para come√ßar:
        if any(keyword in text.lower() for keyword in ['frete', 'entrega', 'dist√¢ncia', 'endere√ßo', 'localiza√ß√£o', 'calcular']):
            conversational_agent = self.specialist_agents['geolocation_specialist']
            logger.info("Roteado para Geolocation Specialist com base em palavras-chave.")
        
        start_time = time.time()
        prompt = self._prepare_text_and_history(text, conversation_history, profile_data, location_data)
        run_response = conversational_agent.run(prompt)
        response_text = run_response.content if hasattr(run_response, 'content') else str(run_response)
        processing_time_ms = int((time.time() - start_time) * 1000)

        logger.info(f"Mensagem de texto processada pelo {conversational_agent.name} em {processing_time_ms}ms.")
        return {
            'success': True,
            'response': response_text,
            'metadata': {'agent_name': conversational_agent.name, 'processing_time_ms': processing_time_ms}
        }

    def process_image_message(self, image_data: bytes, text_prompt: str = "", conversation_history: List[Dict] = None, profile_data: Optional[Dict] = None) -> Dict[str, Any]:
        start_time = time.time()
        agent = self.specialist_agents['visual_analyzer']
        
        # Usa o text_prompt se fornecido, sen√£o usa um prompt padr√£o.
        prompt = self._prepare_text_and_history(text_prompt or "Analise esta imagem em detalhes.", conversation_history, profile_data)
        
        temp_image_path = None
        try:
            # Salva os bytes da imagem em um arquivo tempor√°rio
            fd, temp_image_path = tempfile.mkstemp(suffix=".jpg")
            with os.fdopen(fd, 'wb') as temp_file:
                temp_file.write(image_data)
            
            # Prepara a entrada para o agente no formato esperado
            image_input = [{"filepath": temp_image_path}]
            
            logger.debug(f"Enviando para Visual Analyzer. Prompt: '{prompt[:100]}...', Imagem: {image_input}")
            
            # Executa o agente
            run_response = agent.run(prompt, images=image_input)
            response_text = run_response.content if hasattr(run_response, 'content') else str(run_response)
            
            processing_time_ms = int((time.time() - start_time) * 1000)
            logger.info(f"Imagem processada pelo Visual Analyzer em {processing_time_ms}ms.")
            
            return {
                'success': True,
                'response': response_text,
                'metadata': {'agent_name': 'Visual Analyzer (Shortcut)', 'processing_time_ms': processing_time_ms}
            }
        except Exception as e:
            logger.error(f"Falha ao processar imagem com Visual Analyzer: {str(e)}", exc_info=True)
            return {
                'success': False,
                'error': str(e),
                'response': "Desculpe, a IA encontrou um problema ao analisar a imagem. üò•"
            }
        finally:
            # Garante que o arquivo tempor√°rio seja removido
            if temp_image_path and os.path.exists(temp_image_path):
                os.remove(temp_image_path)
                logger.debug(f"Removed temp image file: {temp_image_path}")

    def process_video_message(self, video_data: bytes, text_prompt: str = "", conversation_history: List[Dict] = None, profile_data: Optional[Dict] = None) -> Dict[str, Any]:
        """Processa uma mensagem de v√≠deo, analisando seu conte√∫do."""
        start_time = time.time()
        agent = self.specialist_agents['visual_analyzer']
        
        prompt = self._prepare_text_and_history(text_prompt or "Analise este v√≠deo em detalhes e descreva o que acontece.", conversation_history, profile_data)
        
        temp_video_path = None
        try:
            # Salva os bytes do v√≠deo em um arquivo tempor√°rio com a extens√£o correta.
            fd, temp_video_path = tempfile.mkstemp(suffix=".mp4")
            with os.fdopen(fd, 'wb') as temp_file:
                temp_file.write(video_data)
            
            video_input = [{"filepath": temp_video_path}]
            logger.debug(f"Enviando para Visual Analyzer. Prompt: '{prompt[:100]}...', V√≠deo: {video_input}")
            
            # Executa o agente, passando o v√≠deo para an√°lise.
            # Assumimos que a biblioteca `agno` suporta o par√¢metro `videos`.
            run_response = agent.run(prompt, videos=video_input)
            response_text = run_response.content if hasattr(run_response, 'content') else str(run_response)
            
            processing_time_ms = int((time.time() - start_time) * 1000)
            logger.info(f"V√≠deo processado pelo Visual Analyzer em {processing_time_ms}ms.")
            
            return {
                'success': True,
                'response': response_text,
                'metadata': {'agent_name': 'Visual Analyzer (Shortcut)', 'processing_time_ms': processing_time_ms}
            }
        except Exception as e:
            logger.error(f"Falha ao processar v√≠deo com Visual Analyzer: {str(e)}", exc_info=True)
            return {
                'success': False,
                'error': str(e),
                'response': "Desculpe, a IA encontrou um problema ao analisar o v√≠deo. üò•"
            }
        finally:
            # Garante que o arquivo de v√≠deo tempor√°rio seja removido
            if temp_video_path and os.path.exists(temp_video_path):
                os.remove(temp_video_path)
                logger.debug(f"Removed temp video file: {temp_video_path}")

    def process_audio_message(self, audio_data: bytes, conversation_history: List[Dict] = None, profile_data: Optional[Dict] = None) -> Dict[str, Any]:
        start_time = time.time()
        agent = self.specialist_agents['audio_processor']
        # A tarefa √© focada na transcri√ß√£o do √°udio fornecido.
        prompt = "Transcreva o √°udio a seguir. Se n√£o for fala, descreva os sons que voc√™ ouve."

        temp_out_path = None
        try:
            # Adicionar uma verifica√ß√£o para garantir que os dados do √°udio n√£o est√£o vazios
            if not audio_data:
                logger.error("process_audio_message received empty audio data. Aborting ffmpeg conversion.")
                return {
                    'success': False,
                    'error': "Empty audio data received, possibly due to a decryption error.",
                    'response': "Desculpe, n√£o consegui processar o √°udio. Parece que houve um problema na descriptografia. üò•"
                }

            # Etapa 1: Em vez de salvar um arquivo tempor√°rio, vamos passar os dados de √°udio
            # diretamente para o stdin do ffmpeg para evitar race conditions no sistema de arquivos.
            fd_out, temp_out_path = tempfile.mkstemp(suffix=".wav")
            os.close(fd_out)  # Fechar o handle para que o ffmpeg possa escrever no caminho

            logger.debug(f"Attempting ffmpeg conversion via stdin to {temp_out_path}")
            
            command = [
                'ffmpeg',
                '-v', 'error',           # Logar apenas erros
                '-f', 'ogg',             # Assumir o formato de cont√™iner OGG para a entrada
                '-c:a', 'libopus',       # EXPLICITAMENTE use o codec libopus para a entrada
                '-i', '-',               # Ler a entrada do stdin (pipe)
                '-acodec', 'pcm_s16le',  # Codec de √°udio de sa√≠da (WAV padr√£o)
                '-ar', '16000',          # Taxa de amostragem de 16kHz (bom para ASR)
                '-ac', '1',              # Um canal de √°udio (mono)
                '-y',                    # Sobrescrever arquivo de sa√≠da
                temp_out_path
            ]
            
            # Executa o comando, passando os bytes do √°udio para o stdin do processo.
            # text=False √© crucial, pois o input e o stderr s√£o tratados como bytes.
            result = subprocess.run(command, input=audio_data, capture_output=True, check=False)

            if result.returncode != 0:
                # Decodificar stderr para logar o erro do ffmpeg de forma leg√≠vel
                stderr_text = result.stderr.decode('utf-8', errors='replace').strip()
                logger.error(f"ffmpeg conversion failed with code {result.returncode}. stderr: {stderr_text}")
                raise Exception(f"ffmpeg failed: {stderr_text}")
            
            logger.debug(f"Successfully converted audio to {temp_out_path}")

            # Etapa 2: Preparar o arquivo WAV convertido para o agente.
            audio_input = [{"filepath": temp_out_path}]

            logger.debug(f"Enviando para Audio Processor. Prompt: '{prompt[:100]}...', Audio (convertido para WAV): {audio_input}")
            
            # Etapa 3: Executar o agente com o √°udio WAV.
            run_response = agent.run(prompt, audio=audio_input)
            transcribed_text = run_response.content if hasattr(run_response, 'content') else str(run_response)
            
            transcription_time_ms = int((time.time() - start_time) * 1000)
            logger.info(f"Audio transcribed in {transcription_time_ms}ms. Text: '{transcribed_text}'")
            
            # Etapa 4: Processar o texto transcrito como uma mensagem de conversa√ß√£o.
            if not transcribed_text or not transcribed_text.strip():
                logger.warning("Transcription resulted in empty text. Sending a default reply.")
            return {
                'success': True,
                    'response': "N√£o consegui entender o que foi dito no √°udio. Pode tentar de novo?", 
                    'metadata': {'agent_name': 'Audio Processor (Shortcut)', 'processing_time_ms': transcription_time_ms}
                }
            
            logger.info("Processing transcribed text with conversational agent.")
            text_processing_result = self.process_text_message(transcribed_text, conversation_history, profile_data)
            
            # Adicionar o texto transcrito ao metadata para que o webhook possa us√°-lo para atualizar o perfil
            if 'metadata' not in text_processing_result:
                text_processing_result['metadata'] = {}
            text_processing_result['metadata']['transcribed_text'] = transcribed_text
            
            return text_processing_result
            
        except Exception as e:
            logger.error(f"Falha ao processar √°udio com Audio Processor: {str(e)}", exc_info=True)
            return {
                'success': False,
                'error': str(e),
                'response': "Desculpe, a IA encontrou um problema ao processar o √°udio. üò•"
            }
        finally:
            # N√£o h√° mais arquivo de entrada tempor√°rio para remover.
            if temp_out_path and os.path.exists(temp_out_path):
                os.remove(temp_out_path)
                logger.debug(f"Removed temp output audio file: {temp_out_path}")
            
    def extract_profile_info(self, text: str) -> Optional[Dict[str, Any]]:
        """
        Usa o agente Profile Manager para extrair informa√ß√µes de perfil do texto.
        Retorna um dicion√°rio estruturado ou None.
        """
        if not text or not text.strip():
            return None
            
        agent = self.specialist_agents.get('profile_manager')
        if not agent:
            logger.error("Agente 'profile_manager' n√£o encontrado.")
            return None
        
        try:
            # O prompt para este agente √© a pr√≥pria mensagem do usu√°rio.
            # O system prompt do agente j√° cont√©m todas as instru√ß√µes.
            run_response = agent.run(text)
            response_content = run_response.content if hasattr(run_response, 'content') else str(run_response)
            
            # A resposta esperada √© um JSON puro.
            logger.debug(f"Profile Manager raw response: {response_content}")

            # Limpa a string JSON de poss√≠veis blocos de c√≥digo markdown.
            clean_json_str = response_content.strip()
            if clean_json_str.startswith("```json"):
                clean_json_str = clean_json_str[7:]
            if clean_json_str.startswith("```"):
                clean_json_str = clean_json_str[3:]
            if clean_json_str.endswith("```"):
                clean_json_str = clean_json_str[:-3]
            clean_json_str = clean_json_str.strip()

            profile_action = json.loads(clean_json_str)
            
            # Valida√ß√£o b√°sica do schema esperado
            if 'action' in profile_action and (profile_action['action'] == 'NONE' or ('data' in profile_action and 'key' in profile_action['data'] and 'value' in profile_action['data'])):
                logger.info(f"Profile Manager extraiu a a√ß√£o: {profile_action}")
                return profile_action
            else:
                logger.warning(f"Profile Manager retornou JSON em formato inesperado: {clean_json_str}")
                return None
                
        except json.JSONDecodeError:
            logger.error(f"Falha ao decodificar a resposta JSON do Profile Manager. Resposta original: '{response_content}', Ap√≥s limpeza: '{clean_json_str}'")
            return None
        except Exception as e:
            logger.error(f"Erro ao extrair informa√ß√µes de perfil: {e}", exc_info=True)
            return None
            
    def _process_with_team(self, text_prompt: str, conversation_history: Optional[List[Dict]] = None, audio_data: Optional[bytes] = None, image_data: Optional[List[bytes]] = None) -> Dict[str, Any]:
        start_time = time.time()
        temp_audio_path = None
        temp_image_paths = []
        try:
            full_prompt = self._prepare_text_and_history(text_prompt, conversation_history)
            
            audio_path_for_run = None
            if audio_data:
                fd, temp_audio_path = tempfile.mkstemp(suffix=".ogg")
                with os.fdopen(fd, 'wb') as temp_file:
                    temp_file.write(audio_data)
                audio_path_for_run = [{"filepath": temp_audio_path}]
            
            image_paths_for_run = None
            if image_data:
                image_paths_for_run = []
                for i, img_bytes in enumerate(image_data):
                    # Usar uma extens√£o de arquivo mais gen√©rica ou detectar o tipo
                    fd, temp_img_path = tempfile.mkstemp(suffix=".jpg") 
                    with os.fdopen(fd, 'wb') as temp_file:
                        temp_file.write(img_bytes)
                    image_paths_for_run.append({"filepath": temp_img_path})
                    temp_image_paths.append(temp_img_path)

            logger.debug(f"Enviando para master_team.run(). Prompt: '{full_prompt[:100]}...', Audio: {audio_path_for_run}, Imagens: {image_paths_for_run}")
            
            team_response_obj = self.team.run(full_prompt, audio=audio_path_for_run, images=image_paths_for_run)
            response_text = team_response_obj.content if hasattr(team_response_obj, 'content') else str(team_response_obj)
            
            processing_time = int((time.time() - start_time) * 1000)
            logger.info(f"Mensagem processada por {self.team.name} em {processing_time}ms.")
            
            metadata = {'agent_name': self.team.name, 'processing_time_ms': processing_time}

            if "[USER_REQUESTS_HUMAN_AGENT]" in response_text:
                metadata['action'] = "REQUEST_HUMAN_AGENT"
            elif "[AI_NEEDS_ASSISTANCE]" in response_text:
                metadata['action'] = "REQUEST_HUMAN_AGENT"
            
            return {
                'success': True,
                'response': response_text,
                'metadata': metadata
            }
        except Exception as e:
            logger.error(f"Falha ao processar mensagem com Agno Master Team: {str(e)}", exc_info=True)
            return {
                'success': False,
                'error': str(e),
                'response': "Desculpe, a equipe de IA encontrou um problema ao processar sua solicita√ß√£o. üò•"
            }
        finally:
            if temp_audio_path and os.path.exists(temp_audio_path):
                os.remove(temp_audio_path)
                logger.debug(f"Removed temp audio file: {temp_audio_path}")
            for path in temp_image_paths:
                if os.path.exists(path):
                    os.remove(path)
                    logger.debug(f"Removed temp image file: {path}")

    def generate_summary(self, conversation_history: List[Dict]) -> str:
        if not conversation_history:
            return "N√£o h√° conversa para resumir."
        
        context = self._build_conversation_context(conversation_history)
        summary_prompt = f"Por favor, gere um resumo conciso desta conversa em um par√°grafo:\n\n{context}"
        
        summary_result_dict = self._process_with_team(text_prompt=summary_prompt)
        return summary_result_dict['response'] if summary_result_dict['success'] else "Erro ao gerar resumo."

    def _build_conversation_context(self, conversation_history: List[Dict]) -> str:
        if not conversation_history:
            return ""
        return "\n".join([f"{('Usu√°rio' if msg['sender_type'] == 'user' else 'Assistente')}: {msg.get('message_text', '')}" for msg in conversation_history])

    def process_location_message(self, latitude: float, longitude: float, conversation_history: List[Dict] = None, profile_data: Optional[Dict] = None) -> Dict[str, Any]:
        """
        Processa uma mensagem de localiza√ß√£o, usando o Geolocation Specialist para pedir o destino.
        """
        logger.info(f"Processando mensagem de localiza√ß√£o: lat={latitude}, lon={longitude}")
        
        # O texto √© um placeholder para acionar o fluxo, mas o contexto principal vem dos dados de localiza√ß√£o.
        text_prompt = "O usu√°rio enviou uma localiza√ß√£o."
        location_data = {"latitude": latitude, "longitude": longitude}
        
        # For√ßar o uso do agente de geolocaliza√ß√£o para este tipo de mensagem.
        agent = self.specialist_agents['geolocation_specialist']
        
        start_time = time.time()
        prompt = self._prepare_text_and_history(text_prompt, conversation_history, profile_data, location_data)
        
        run_response = agent.run(prompt)
        response_text = run_response.content if hasattr(run_response, 'content') else str(run_response)
        processing_time_ms = int((time.time() - start_time) * 1000)

        logger.info(f"Localiza√ß√£o processada pelo Geolocation Specialist em {processing_time_ms}ms.")
        return {
            'success': True,
            'response': response_text,
            'metadata': {'agent_name': agent.name, 'processing_time_ms': processing_time_ms}
        }
