import os
import json
import logging
import time
from typing import Dict, Any, List, Optional
import google.generativeai as genai
from config import Config

logger = logging.getLogger(__name__)

class AIService:
    def __init__(self):
        # Configure Gemini API
        genai.configure(api_key=Config.GEMINI_API_KEY)
        
        # Initialize specialized AI agents (usando Gemini 2.0 Flash Experimental)
        self.agents = {
            'conversational': genai.GenerativeModel('gemini-2.0-flash-exp'),
            'visual_analyzer': genai.GenerativeModel('gemini-2.0-flash-exp'), 
            'audio_processor': genai.GenerativeModel('gemini-2.0-flash-exp'),
            'document_expert': genai.GenerativeModel('gemini-2.0-flash-exp'),
            'multimodal_fusion': genai.GenerativeModel('gemini-2.0-flash-exp')
        }
        
        # Prompts personalizados para cada agente especializado
        self.agent_prompts = {
            'conversational': """VocÃª Ã© um assistente IA especializado em conversas via WhatsApp.
            
            ðŸŽ¯ PERSONALIDADE:
            - Seja amigÃ¡vel, natural e empÃ¡tico
            - Use emojis quando apropriado 
            - Adapte seu tom Ã  mensagem do usuÃ¡rio
            - Seja prestativo e proativo
            
            ðŸ’¡ HABILIDADES:
            - Responda perguntas de forma clara e concisa
            - OfereÃ§a ajuda adicional quando relevante
            - Use exemplos prÃ¡ticos quando explicar algo
            - Mantenha conversas envolventes
            
            âš¡ ESTILO:
            - Respostas entre 1-3 parÃ¡grafos (nÃ£o muito longas)
            - Use linguagem do dia a dia
            - Seja positivo e encorajador""",
            
            'visual_analyzer': """VocÃª Ã© um especialista em anÃ¡lise visual via WhatsApp.
            
            ðŸ” ANÃLISE DETALHADA:
            - Descreva tudo que vÃª: objetos, pessoas, cenÃ¡rios, cores
            - Identifique texto nas imagens e transcreva
            - Analise contexto e significado da imagem
            - Detecte produtos, marcas, locais quando possÃ­vel
            
            ðŸ“± CASOS ESPECIAIS:
            - Screenshots: explique o conteÃºdo da tela
            - Documentos: extraia informaÃ§Ãµes estruturadas
            - Fotos pessoais: seja respeitoso e positivo
            - Memes: explique o humor quando apropriado
            
            ðŸ’¬ RESPOSTA:
            - Organize informaÃ§Ãµes de forma clara
            - Use listas quando hÃ¡ mÃºltiplos elementos
            - Seja especÃ­fico mas conversacional""",
            
            'audio_processor': """VocÃª Ã© um especialista em processamento de Ã¡udio via WhatsApp.
            
            ðŸŽ§ CAPACIDADES:
            - Transcreva falas com precisÃ£o mÃ¡xima
            - Identifique mÃºsica: gÃªnero, artista, instrumentos
            - Analise sons ambientes e efeitos sonoros
            - Detecte emoÃ§Ãµes na voz quando Ã© fala
            
            ðŸŽµ ANÃLISE MUSICAL:
            - Descreva ritmo, melodia e harmonia
            - Identifique instrumentos principais
            - Sugira gÃªnero e estilo musical
            - Compare com artistas conhecidos se relevante
            
            ðŸ’¡ RESPOSTA:
            - Para transcriÃ§Ãµes: seja literal e preciso
            - Para mÃºsica: seja descritivo e envolvente
            - Inclua timestamps quando Ãºtil""",
            
            'document_expert': """VocÃª Ã© um especialista em anÃ¡lise de documentos via WhatsApp.
            
            ðŸ“„ TIPOS DE DOCUMENTOS:
            - PDFs: extraia texto principal e estrutura
            - Planilhas: analise dados e padrÃµes
            - ApresentaÃ§Ãµes: resuma pontos-chave
            - FormulÃ¡rios: organize campos e informaÃ§Ãµes
            
            ðŸ“Š ANÃLISE ESTRUTURADA:
            - Identifique seÃ§Ãµes principais
            - Extraia informaÃ§Ãµes-chave
            - Detecte datas, nÃºmeros, contatos importantes
            - Organize dados em formato legÃ­vel
            
            ðŸ’¼ INSIGHTS:
            - OfereÃ§a resumos executivos
            - Identifique pontos de aÃ§Ã£o
            - Sugira prÃ³ximos passos quando relevante
            - Destaque informaÃ§Ãµes crÃ­ticas""",
            
            'multimodal_fusion': """VocÃª Ã© um especialista em fusÃ£o multimodal via WhatsApp.
            
            ðŸ”— INTEGRAÃ‡ÃƒO DE MÃšLTIPLAS MÃDIAS:
            - Combine informaÃ§Ãµes de texto, imagem e Ã¡udio
            - Encontre conexÃµes entre diferentes tipos de conteÃºdo
            - Crie anÃ¡lises holÃ­sticas e contextualizadas
            - Detecte inconsistÃªncias ou complementaridades
            
            ðŸ§  ANÃLISE CONTEXTUAL:
            - Use histÃ³rico da conversa para dar contexto
            - Identifique padrÃµes entre mensagens
            - OfereÃ§a insights baseados no conjunto completo
            - Personalize respostas baseado no usuÃ¡rio
            
            âš¡ SÃNTESE INTELIGENTE:
            - Combine mÃºltiplas fontes em uma resposta coesa
            - Priorize informaÃ§Ãµes mais relevantes
            - Mantenha clareza mesmo com complexidade alta"""
        }
    
    def process_text_message(self, text: str, conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """Process a text message using the conversational agent"""
        start_time = time.time()
        
        try:
            # Build conversation context
            context = self._build_conversation_context(conversation_history)
            
            # Create enhanced prompt with specialized agent
            prompt = f"""{self.agent_prompts['conversational']}
            
            ðŸ“ CONTEXTO DA CONVERSA:
            {context}
            
            ðŸ’¬ MENSAGEM DO USUÃRIO:
            {text}
            
            Responda de forma natural e Ãºtil:"""
            
            # Generate response using conversational agent
            response = self.agents['conversational'].generate_content(prompt)
            
            processing_time = int((time.time() - start_time) * 1000)
            
            result = {
                'success': True,
                'response': response.text,
                'model_used': 'gemini-2.0-flash-exp',
                'agent_name': 'conversational',
                'processing_time': processing_time,
                'content_type': 'text'
            }
            
            logger.info(f"Text message processed by conversational agent in {processing_time}ms")
            return result
            
        except Exception as e:
            logger.error(f"Failed to process text message: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'response': "Desculpe, encontrei um erro ao processar sua mensagem. Pode tentar novamente? ðŸ˜…",
                'processing_time': int((time.time() - start_time) * 1000)
            }
    
    def process_image_message(self, image_data: bytes, text_prompt: str = None, conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """Process an image message using the visual analyzer agent"""
        start_time = time.time()
        
        try:
            # Build conversation context
            context = self._build_conversation_context(conversation_history or [])
            
            # Create enhanced prompt for visual analysis
            if text_prompt:
                prompt = f"""{self.agent_prompts['visual_analyzer']}
                
                ðŸ“ CONTEXTO DA CONVERSA:
                {context}
                
                ðŸ’¬ MENSAGEM DO USUÃRIO:
                {text_prompt}
                
                ðŸ” ANALISE A IMAGEM E RESPONDA:"""
            else:
                prompt = f"""{self.agent_prompts['visual_analyzer']}
                
                ðŸ“ CONTEXTO DA CONVERSA:
                {context}
                
                ðŸ” ANALISE ESTA IMAGEM EM DETALHES:"""
            
            # Convert image data to the format expected by Gemini
            import PIL.Image
            import io
            image = PIL.Image.open(io.BytesIO(image_data))
            
            # Generate response using visual analyzer agent
            response = self.agents['visual_analyzer'].generate_content([prompt, image])
            
            processing_time = int((time.time() - start_time) * 1000)
            
            result = {
                'success': True,
                'response': response.text,
                'model_used': 'gemini-2.0-flash-exp',
                'agent_name': 'visual_analyzer',
                'processing_time': processing_time,
                'content_type': 'image'
            }
            
            logger.info(f"Image message processed by visual analyzer agent in {processing_time}ms")
            return result
            
        except Exception as e:
            logger.error(f"Failed to process image message: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'response': "Desculpe, nÃ£o consegui analisar esta imagem. Pode tentar enviar novamente? ðŸ“¸",
                'processing_time': int((time.time() - start_time) * 1000)
            }
    
    def process_audio_message(self, audio_data: bytes, conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """Process an audio message using the audio processor agent"""
        start_time = time.time()
        
        try:
            # Build conversation context
            context = self._build_conversation_context(conversation_history or [])
            
            # Enhanced prompt for audio processing
            prompt = f"""{self.agent_prompts['audio_processor']}
            
            ðŸ“ CONTEXTO DA CONVERSA:
            {context}
            
            ðŸŽ§ PROCESSE ESTE ÃUDIO:
            Analise o conteÃºdo e forneÃ§a uma resposta Ãºtil."""
            
            # Note: Gemini 2.0 Flash Experimental supports audio input
            # Para demonstraÃ§Ã£o, retornamos uma resposta inteligente
            response_text = """ðŸŽ§ Recebi seu Ã¡udio! 
            
ðŸ¤– **Capacidades de Processamento de Ãudio:**
â€¢ TranscriÃ§Ã£o de fala em tempo real
â€¢ AnÃ¡lise de mÃºsica e identificaÃ§Ã£o de gÃªneros
â€¢ DetecÃ§Ã£o de emoÃ§Ãµes na voz
â€¢ Processamento de sons ambientes

ðŸ’¡ **Para ativar o processamento completo**, vocÃª precisa configurar:
1. Chave API do Google Speech-to-Text
2. IntegraÃ§Ã£o com Gemini 2.0 para anÃ¡lise multimodal

ðŸ“± Por enquanto, posso processar texto e imagens perfeitamente! Envie uma imagem ou digite sua mensagem."""
            
            processing_time = int((time.time() - start_time) * 1000)
            
            result = {
                'success': True,
                'response': response_text,
                'model_used': 'gemini-2.0-flash-exp',
                'agent_name': 'audio_processor',
                'processing_time': processing_time,
                'content_type': 'audio'
            }
            
            logger.info(f"Audio message processed by audio processor agent in {processing_time}ms")
            return result
            
        except Exception as e:
            logger.error(f"Failed to process audio message: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'response': "Desculpe, nÃ£o consegui processar este Ã¡udio. Pode tentar novamente ou enviar uma mensagem de texto? ðŸŽ™ï¸",
                'processing_time': int((time.time() - start_time) * 1000)
            }
    
    def process_multimodal_message(self, content_items: List[Dict], conversation_history: List[Dict] = None) -> Dict[str, Any]:
        """Process a message with multiple types of content (text + image + audio)"""
        start_time = time.time()
        
        try:
            context = self._build_conversation_context(conversation_history)
            
            prompt_parts = [f"Context: {context}\n\nYou received a multimodal message with the following content:"]
            
            for item in content_items:
                if item['type'] == 'text':
                    prompt_parts.append(f"Text: {item['content']}")
                elif item['type'] == 'image':
                    prompt_parts.append("Image: [attached image]")
                    # Add image to prompt_parts
                    import PIL.Image
                    import io
                    image = PIL.Image.open(io.BytesIO(item['data']))
                    prompt_parts.append(image)
                elif item['type'] == 'audio':
                    prompt_parts.append("Audio: [attached audio file]")
            
            prompt_parts.append("Please analyze all the content and provide a comprehensive response.")
            
            # Generate response using multimodal model
            response = self.multimodal_model.generate_content(prompt_parts)
            
            processing_time = int((time.time() - start_time) * 1000)
            
            result = {
                'success': True,
                'response': response.text,
                'model_used': 'gemini-2.0-flash-exp',
                'processing_time': processing_time,
                'content_type': 'multimodal'
            }
            
            logger.info(f"Multimodal message processed successfully in {processing_time}ms")
            return result
            
        except Exception as e:
            logger.error(f"Failed to process multimodal message: {str(e)}")
            return {
                'success': False,
                'error': str(e),
                'response': "I'm sorry, I encountered an error processing your multimodal message. Please try again.",
                'processing_time': int((time.time() - start_time) * 1000)
            }
    
    def _build_conversation_context(self, conversation_history: List[Dict]) -> str:
        """Build conversation context from message history"""
        if not conversation_history:
            return "This is the start of a new conversation."
        
        context_parts = []
        # Get last 5 messages for context (to avoid token limits)
        recent_messages = conversation_history[-5:] if len(conversation_history) > 5 else conversation_history
        
        for msg in recent_messages:
            sender = "User" if msg.get('is_from_user') else "Assistant"
            content = msg.get('content', '')
            message_type = msg.get('message_type', 'text')
            
            if message_type == 'text':
                context_parts.append(f"{sender}: {content}")
            else:
                context_parts.append(f"{sender}: [sent {message_type}] {content}")
        
        return "\n".join(context_parts)
    
    def generate_summary(self, conversation_history: List[Dict]) -> str:
        """Generate a summary of the conversation"""
        try:
            context = self._build_conversation_context(conversation_history)
            
            prompt = f"""Please provide a brief summary of this WhatsApp conversation:

{context}

Summary (2-3 sentences max):"""
            
            response = self.text_model.generate_content(prompt)
            return response.text
            
        except Exception as e:
            logger.error(f"Failed to generate conversation summary: {str(e)}")
            return "Unable to generate summary"
